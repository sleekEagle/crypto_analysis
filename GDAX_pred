#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue May 15 16:05:55 2018

@author: sleek_eagle
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import datetime
from pandas.tools.plotting import autocorrelation_plot
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error
from scipy.stats.stats import pearsonr 
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPRegressor
from NNpred import prepData
from NNpred import getF_and_V_data
from NNpred import trainNN
from NNpred import scaleData
from NNpred import scale_each_vector
from NNpred import get_scaler_data
from NNpred import scale_from_scalers
from NNpred import inverse_scale_from_scalers
from sklearn.metrics import mean_squared_error
from sklearn import datasets, linear_model



  
datapath = "/home/sleek_eagle/research/crypto/1hrdata_filled.csv"
data = pd.read_csv(datapath,sep=',')
data['datetime'] = data['datetime'].str[:10]
#prepare hourly data
data = data.groupby(['datetime']).mean().reset_index()
data['diff_price'] = data['avg_price'].diff()
data = data.iloc[600:799,:]


df = data[['datetime','avg_price']].dropna(axis=0, how='any')
df.columns = ['date','avg_price']
lookback = 7
pdata = prepData(df,lookback)
[train_f,train_v,test_f,test_v,train_dates,test_dates] = getF_and_V_data(pdata,0.6)
#check last day prediction
#pred_last(test_f,test_v)

[train_f_scaled,train_v_scaled] = scale_each_vector(train_f,train_v)
[test_f_scaled,scalers] = get_scaler_data(test_f)
test_v_scaled = scale_from_scalers(test_v,scalers)
test_v = test_v.reset_index().drop(columns = ['index'] )

#regression prediction
regr = linear_model.LinearRegression()
regr.fit(train_f_scaled, train_v_scaled)
regr_pred = pd.DataFrame(regr.predict(test_f_scaled))
pred = inverse_scale_from_scalers(regr_pred,scalers)
#plt.figure()
plt.plot(test_v)
plt.plot(pred)
error = math.sqrt(mean_squared_error(test_v,pred))
print(error)




[error,pred] = trainNN((200),0.00001,train_f_scaled,train_v_scaled,test_f_scaled,test_v_scaled)
pred = inverse_scale_from_scalers(pred['pred'],scalers)#plt.figure()
plt.plot(test_v)
plt.plot(pred)
error = math.sqrt(mean_squared_error(test_v,pred))
print(error)




for i in range(1,1200,50):
    print(i)
    [error,pred] = trainNN((i),0.00001,train_f_scaled,train_v_scaled,test_f_scaled,test_v_scaled)
    #rescaled to real values
    pred = inverse_scale_from_scalers(pred['pred'],scalers)
    #plt.figure()
    #plt.plot(test_v)
    #plt.plot(pred)
    error = math.sqrt(mean_squared_error(test_v,pred))
    print(error)
    
errors = test_v['100'] - pred


plt.hist(errors)


def scaleData(row):
    f = row[0:row.shape[0]-1]
    v = row[row.shape[0]-1]
    #min max scaler
    f_scaled = (f - min(f))/(1 + max(f) - min(f))
    v_scaled = (v - min(f))/(1 + max(f) - min(f))
    s = f_scaled.append(pd.Series(v_scaled))
    s=s.reset_index().drop(['index'],axis = 1)
    s=pd.Series(s[0])
    return s

#predict last data point as the prediction
def pred_last(test_f,test_v):
    last = test_f.iloc[:,(test_f.shape[1]-1)]
    actual = test_v
    plt.figure()
    plt.plot(actual)
    plt.plot(last)
    print(math.sqrt(mean_squared_error(actual,last)))

